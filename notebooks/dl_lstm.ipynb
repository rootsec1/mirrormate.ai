{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the board to a flat list\n",
    "def board_to_flat_list(board):\n",
    "    # Get the board as a string in ASCII format\n",
    "    board_string = board.__str__()\n",
    "    # Split the board string into rows\n",
    "    rows = board_string.split(\"\\n\")\n",
    "    # Initialize an empty list to store the flat board\n",
    "    flat_list = []\n",
    "    # Iterate through each row\n",
    "    for row in rows:\n",
    "        # Split the row by spaces to get individual pieces\n",
    "        pieces = row.split(\" \")\n",
    "        # Extend the flat list with the pieces\n",
    "        flat_list.extend(pieces)\n",
    "\n",
    "    # Replace \".\" with None\n",
    "    flat_list = [None if piece == \".\" else piece for piece in flat_list]\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "# Vocabulary\n",
    "def get_vocabulary() -> tuple[dict, dict]:\n",
    "    fresh_chess_board = chess.Board()\n",
    "    # Get all unique characters in fresh_chess_board\n",
    "    unique_characters = list(set(fresh_chess_board.board_fen()))\n",
    "    unique_characters = [char for char in unique_characters if char.isalpha()]\n",
    "    unique_characters.sort()\n",
    "    vocabulary_dict = {char: i+1 for i, char in enumerate(unique_characters)}\n",
    "    vocabulary_dict[\"EMPTY\"] = -1\n",
    "    reverse_vocabulary_dict = {i: char for char, i in vocabulary_dict.items()}\n",
    "    return vocabulary_dict, reverse_vocabulary_dict\n",
    "\n",
    "\n",
    "# For all values in X, transform string to int using vocabulary_dict\n",
    "def encode_df(df: pd.DataFrame, vocabulary_dict: dict) -> pd.DataFrame:\n",
    "    df = df.fillna(\"EMPTY\")\n",
    "    df = df.map(lambda x: vocabulary_dict[x] if x in vocabulary_dict else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def decode_model_prediction(prediction_list: list, reverse_vocabulary_dict: dict) -> list[str]:\n",
    "    ret_list = [reverse_vocabulary_dict[i] for i in prediction_list]\n",
    "    # If ret_list contains \"EMPTY\", replace it with None\n",
    "    ret_list = [None if x == \"EMPTY\" else x for x in ret_list]\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "def determine_game_stage(move_number):\n",
    "    # 0-10 early game\n",
    "    # 11-30 mid game\n",
    "    # 31+ end game\n",
    "    if move_number <= 10:\n",
    "        return 1\n",
    "    elif move_number <= 30:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def create_dataset(lichess_username: str) -> pd.DataFrame:\n",
    "    data_df = pd.read_csv(f\"../data/raw/games_{lichess_username}.csv\")\n",
    "    output_df = pd.DataFrame()\n",
    "    game_list = []\n",
    "\n",
    "    game_id_stage_count_map = {}\n",
    "    for game_id in data_df[\"game_id\"].unique():\n",
    "        game_id_stage_count_map[str(game_id)] = 0\n",
    "\n",
    "    for idx, row in data_df.iterrows():\n",
    "        game_id = str(row.get(\"game_id\"))\n",
    "        white_player = row.get(\"white_player\")\n",
    "        move_list = row.get(\"move_list\")\n",
    "\n",
    "        if isinstance(move_list, float):\n",
    "            continue\n",
    "\n",
    "        move_list = move_list.split(\" \")\n",
    "\n",
    "        generator_start_index = 0 if white_player == lichess_username else 1\n",
    "        for move_idx in range(generator_start_index, len(move_list), 2):\n",
    "            game_id_stage_count_map[game_id] += 1\n",
    "            move_number = game_id_stage_count_map.get(game_id)\n",
    "            game_stage = determine_game_stage(move_number)\n",
    "\n",
    "            target_move = move_list[move_idx]\n",
    "            input_sequence_list = move_list[:move_idx]\n",
    "\n",
    "            board = chess.Board()\n",
    "            for input_move in input_sequence_list:\n",
    "                board.push_san(input_move)\n",
    "\n",
    "            board_flat_list = [game_id]\n",
    "            board_flat_list.extend(board_to_flat_list(board))\n",
    "            board_flat_list.append(game_stage)\n",
    "            board_flat_list.append(target_move)\n",
    "            game_list.append(board_flat_list)\n",
    "\n",
    "    output_df = pd.DataFrame(game_list)\n",
    "    # Rename first col to game_id and last col to target_move\n",
    "    output_df = output_df.rename(\n",
    "        columns={\n",
    "            0: \"game_id\",\n",
    "            len(output_df.columns)-1: \"target_move\",\n",
    "            len(output_df.columns)-2: \"game_stage\"\n",
    "        }\n",
    "    )\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# Split dataset into train and validation\n",
    "def get_dataset_split(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    # Assuming df is your DataFrame and has columns for features and 'game_id'\n",
    "    X = df.drop(['target_move', 'game_id'], axis=1).values  # Features\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    y = df['target_move'].values\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)  # Use long for classification targets\n",
    "\n",
    "    # Use GroupShuffleSplit to keep games together\n",
    "    gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=0)\n",
    "    train_idx, val_idx = next(gss.split(X, y, groups=df['game_id']))\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    print(\"X_train\")\n",
    "    display(X_train)\n",
    "    print(\"y_train\")\n",
    "    display(y_train)\n",
    "\n",
    "    print(\"Shapes:\", X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "class ChessLSTMN(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_dim, seq_length, num_layers=1):\n",
    "        super(ChessLSTMN, self).__init__()\n",
    "        # LSTM specific parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(num_features, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim, 1024)  # Adjusted for LSTM output\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_dim)\n",
    "        \n",
    "        # Reshape output from the LSTM layer\n",
    "        out = out.reshape(out.shape[0], -1)  # Reshape to fit the following dense layer\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = F.relu(self.bn1(self.fc1(out)))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.bn2(self.fc2(out)))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.bn3(self.fc3(out)))\n",
    "        out = self.fc4(out)  # No activation before CrossEntropyLoss\n",
    "        return out\n",
    "    \n",
    "def train_and_test_data_loader(X_train, X_test, y_train, y_test):\n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = ChessDataset(X_train, y_train)\n",
    "    test_dataset = ChessDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train_model(df: pd.DataFrame):\n",
    "    X_train, X_val, y_train, y_val = get_dataset_split(df)\n",
    "\n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(le.classes_)\n",
    "    hidden_dim = 128  # Example, you can adjust this\n",
    "    seq_length = 10   # Example, adjust based on your data and how many moves back you want to consider\n",
    "    num_layers = 2    # Example, adjust as needed\n",
    "    print(\"Num features:\", num_features)\n",
    "    print(\"Num classes:\", num_classes)\n",
    "    model = ChessLSTMN(num_features, num_classes, hidden_dim, seq_length, num_layers)\n",
    "\n",
    "    train_loader, test_loader = train_and_test_data_loader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    # Set up loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for features, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "            running_acc += (outputs.argmax(1) == labels).float().sum()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_acc / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Evaluation mode\n",
    "    model.eval() \n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: nn.Module, model_name: str):\n",
    "    torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8052,  1.7095,  1.0135,  ...,  1.2567,  1.2591, -1.2115],\n",
       "        [ 0.8052,  1.7095,  1.0135,  ...,  1.2567,  1.2591, -1.2115],\n",
       "        [ 0.8052,  1.7095,  1.0135,  ...,  1.2567,  1.2591, -1.2115],\n",
       "        ...,\n",
       "        [-1.2527, -0.5491, -0.8329,  ...,  0.7127, -0.8031,  1.5685],\n",
       "        [-1.2527, -0.5491, -0.8329,  ..., -0.9195, -0.8031,  1.5685],\n",
       "        [-1.2527, -0.5491, -0.8329,  ..., -0.9195, -0.8031,  1.5685]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1763,  517, 1785,  ...,  289,  418,  480])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: torch.Size([42960, 65]) torch.Size([11109, 65]) torch.Size([42960]) torch.Size([11109])\n",
      "Num features: 65\n",
      "Num classes: 1938\n",
      "Epoch 1/40, Loss: 5.8694, Accuracy: 0.1009\n",
      "Epoch 2/40, Loss: 5.3894, Accuracy: 0.1488\n",
      "Epoch 3/40, Loss: 5.1039, Accuracy: 0.1752\n",
      "Epoch 4/40, Loss: 4.8486, Accuracy: 0.1989\n",
      "Epoch 5/40, Loss: 4.6200, Accuracy: 0.2177\n",
      "Epoch 6/40, Loss: 4.4107, Accuracy: 0.2352\n",
      "Epoch 7/40, Loss: 4.2140, Accuracy: 0.2528\n",
      "Epoch 8/40, Loss: 4.0369, Accuracy: 0.2672\n",
      "Epoch 9/40, Loss: 3.8620, Accuracy: 0.2837\n",
      "Epoch 10/40, Loss: 3.7123, Accuracy: 0.3004\n",
      "Epoch 11/40, Loss: 3.5610, Accuracy: 0.3157\n",
      "Epoch 12/40, Loss: 3.4268, Accuracy: 0.3320\n",
      "Epoch 13/40, Loss: 3.3002, Accuracy: 0.3467\n",
      "Epoch 14/40, Loss: 3.1834, Accuracy: 0.3620\n",
      "Epoch 15/40, Loss: 3.0634, Accuracy: 0.3780\n",
      "Epoch 16/40, Loss: 2.9739, Accuracy: 0.3910\n",
      "Epoch 17/40, Loss: 2.8754, Accuracy: 0.4053\n",
      "Epoch 18/40, Loss: 2.7773, Accuracy: 0.4208\n",
      "Epoch 19/40, Loss: 2.7078, Accuracy: 0.4313\n",
      "Epoch 20/40, Loss: 2.6131, Accuracy: 0.4433\n",
      "Epoch 21/40, Loss: 2.5346, Accuracy: 0.4576\n",
      "Epoch 22/40, Loss: 2.4649, Accuracy: 0.4677\n",
      "Epoch 23/40, Loss: 2.3959, Accuracy: 0.4784\n",
      "Epoch 24/40, Loss: 2.3168, Accuracy: 0.4922\n",
      "Epoch 25/40, Loss: 2.2652, Accuracy: 0.5008\n",
      "Epoch 26/40, Loss: 2.2037, Accuracy: 0.5092\n",
      "Epoch 27/40, Loss: 2.1649, Accuracy: 0.5155\n",
      "Epoch 28/40, Loss: 2.1015, Accuracy: 0.5290\n",
      "Epoch 29/40, Loss: 2.0626, Accuracy: 0.5345\n",
      "Epoch 30/40, Loss: 2.0085, Accuracy: 0.5463\n",
      "Epoch 31/40, Loss: 1.9585, Accuracy: 0.5512\n",
      "Epoch 32/40, Loss: 1.9205, Accuracy: 0.5572\n",
      "Epoch 33/40, Loss: 1.8849, Accuracy: 0.5628\n",
      "Epoch 34/40, Loss: 1.8511, Accuracy: 0.5718\n",
      "Epoch 35/40, Loss: 1.8220, Accuracy: 0.5791\n",
      "Epoch 36/40, Loss: 1.7758, Accuracy: 0.5841\n",
      "Epoch 37/40, Loss: 1.7336, Accuracy: 0.5913\n",
      "Epoch 38/40, Loss: 1.7028, Accuracy: 0.5989\n",
      "Epoch 39/40, Loss: 1.6683, Accuracy: 0.6064\n",
      "Epoch 40/40, Loss: 1.6350, Accuracy: 0.6099\n",
      "Accuracy: 9.23%\n"
     ]
    }
   ],
   "source": [
    "lichess_username = \"ritutoshniwal\"\n",
    "vocabulary_dict, reverse_vocabulary_dict = get_vocabulary()\n",
    "\n",
    "dataset_df = create_dataset(lichess_username)\n",
    "dataset_df = encode_df(dataset_df, vocabulary_dict)\n",
    "model = train_model(dataset_df)\n",
    "\n",
    "save_model(model, \"../models/chess_nn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
